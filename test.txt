qwen3-embedding:8b 4.7GB

1. gpt-oss:120b 65GB

time=2025-12-14T16:55:04.978Z level=INFO source=ggml.go:482 msg="offloading 26 repeating layers to GPU"
time=2025-12-14T16:55:04.978Z level=INFO source=ggml.go:486 msg="offloading output layer to CPU"
time=2025-12-14T16:55:04.978Z level=INFO source=ggml.go:494 msg="offloaded 20/37 layers to GPU"
time=2025-12-14T16:55:04.978Z level=INFO source=device.go:240 msg="model weights" device=CUDA0 size="21.2 GiB"
time=2025-12-14T16:55:04.978Z level=INFO source=device.go:240 msg="model weights" device=CUDA1 size="21.2 GiB"
time=2025-12-14T16:55:04.978Z level=INFO source=device.go:245 msg="model weights" device=CPU size="18.5 GiB"
time=2025-12-14T16:55:04.978Z level=INFO source=device.go:251 msg="kv cache" device=CUDA0 size="326.7 MiB"
time=2025-12-14T16:55:04.978Z level=INFO source=device.go:251 msg="kv cache" device=CUDA1 size="343.2 MiB"
time=2025-12-14T16:55:04.979Z level=INFO source=device.go:256 msg="kv cache" device=CPU size="257.7 MiB"
time=2025-12-14T16:55:04.979Z level=INFO source=device.go:262 msg="compute graph" device=CUDA0 size="834.7 MiB"
time=2025-12-14T16:55:04.979Z level=INFO source=device.go:262 msg="compute graph" device=CUDA1 size="259.8 MiB"
time=2025-12-14T16:55:04.979Z level=INFO source=device.go:267 msg="compute graph" device=CPU size="5.6 MiB"
time=2025-12-14T16:55:04.979Z level=INFO source=device.go:272 msg="total memory" size="62.8 GiB"
time=2025-12-14T16:55:04.979Z level=INFO source=sched.go:517 msg="loaded runners" count=1




